{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sign Language Alphabet Detection and Classification\n\n### Jarred Priester\n### 9/11/22","metadata":{}},{"cell_type":"markdown","source":"1. Introduction\n    - 1.1 Overview\n    - 1.2 About the Data\n    - 1.3 Purpose of this Project\n2. Downloading the Data\n    - 2.1 Downloading the Libraries\n    - 2.2 Downloading the Training Images\n    - 2.3 Downloading the Test Images\n    - 2.4 Checking for Missing Data\n3. Processing the Images\n    - 3.1 Creating our X and our Y\n    - 3.2 Scaling Our Images\n    - 3.3 Reshaping Our Images\n    - 3.4 Distribution of Labels\n4. Viewing the Images\n    - 4.1 Training Images\n    - 4.2 Test Images\n5. CNN Model\n    - 5.1 Spliting Our Training Data\n    - 5.2 Creating Our Model\n    - 5.3 Training Our Model\n6. Results\n    - 6.1 Classification Report\n    - 6.2 Brief Thoughts on Results\n7. Conclusion\n    - 7.1 Recap\n    - 7.2 Future Work","metadata":{}},{"cell_type":"markdown","source":"# 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Overview","metadata":{}},{"cell_type":"markdown","source":"Artifical Intelligence is a tool that has the potential to make our lives easier and, in some cases, remove obstacles. For example, artifical intelligence could be used to take video feeds of people using sign language and translating the signs into words. This could help remove communication obstacles with sign lanuage users with their coworkers and personal relationships.\n\nSuch an application would consist of computer vision and natural language processing, but the first step would be to accurately detect and classify sign language signs using computer vision.\n\nIn this notebook we will be applying a convolutional neural network to classify a dataset of American Sign Language alphabet images. ","metadata":{}},{"cell_type":"markdown","source":"### 1.2 About the Data","metadata":{}},{"cell_type":"markdown","source":"The dataset consist of 27,455 training images and 7,172 test images. Each image is grayscaled and has a 28 x 28 pixel structure. Each images includes the label of which letter in the alphabet the image represents. There are 24 letters in this dataset, 'j' and 'z' are not included because they both involve motion.","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Purpose of this Project","metadata":{}},{"cell_type":"markdown","source":"Our task will be to create a CNN model that can accuractly predict the alphabet letter for each image. I am setting out to achive an accuracy of at least 98%.","metadata":{}},{"cell_type":"markdown","source":"# 2. Downloading the Data","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Downloading the Libraries","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport numpy as np \nimport pandas as pd\nimport random as rd\n\n#data visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nfrom PIL import Image\n\n#for the CNN model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#setting seed for reproducability\nfrom numpy.random import seed\nseed(10)\ntf.random.set_seed(20)\n\n#for viewing filenames\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:24.31291Z","iopub.execute_input":"2022-09-11T15:08:24.314004Z","iopub.status.idle":"2022-09-11T15:08:29.140241Z","shell.execute_reply.started":"2022-09-11T15:08:24.313897Z","shell.execute_reply":"2022-09-11T15:08:29.138748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Downloading the Training Images","metadata":{}},{"cell_type":"code","source":"#downloading the training data\ntrain = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:29.148268Z","iopub.execute_input":"2022-09-11T15:08:29.149055Z","iopub.status.idle":"2022-09-11T15:08:34.43973Z","shell.execute_reply.started":"2022-09-11T15:08:29.148998Z","shell.execute_reply":"2022-09-11T15:08:34.43709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Downloading the Test Images","metadata":{}},{"cell_type":"code","source":"#downloading the test data\ntest = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_test.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:34.44165Z","iopub.execute_input":"2022-09-11T15:08:34.442219Z","iopub.status.idle":"2022-09-11T15:08:35.369957Z","shell.execute_reply.started":"2022-09-11T15:08:34.44217Z","shell.execute_reply":"2022-09-11T15:08:35.36863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 Checking for Missing Data","metadata":{}},{"cell_type":"code","source":"#summing the number of na in the training set for each column\nprint(sum(train.isna().sum()))\n\n#summing the number of na in the test set for each column\nprint(sum(test.isna().sum()))","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.374552Z","iopub.execute_input":"2022-09-11T15:08:35.375351Z","iopub.status.idle":"2022-09-11T15:08:35.437327Z","shell.execute_reply.started":"2022-09-11T15:08:35.375297Z","shell.execute_reply":"2022-09-11T15:08:35.43563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#summing the number of null values in the training set for each column\nprint(sum(train.isnull().sum()))\n\n#summing the number of null values in the test set for each column\nprint(sum(test.isnull().sum()))","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.439199Z","iopub.execute_input":"2022-09-11T15:08:35.440018Z","iopub.status.idle":"2022-09-11T15:08:35.510944Z","shell.execute_reply.started":"2022-09-11T15:08:35.43995Z","shell.execute_reply":"2022-09-11T15:08:35.509826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Processing the Images","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Creating our X and our Y","metadata":{}},{"cell_type":"markdown","source":"The first column in the dataset is the labels. We will first separate the label and pixel data.","metadata":{}},{"cell_type":"code","source":"#creating our Y for the training data\nY_train = train[\"label\"]\n\n#creating our X for the training data\nX_train = train.drop(labels = [\"label\"],axis = 1) ","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.512814Z","iopub.execute_input":"2022-09-11T15:08:35.513574Z","iopub.status.idle":"2022-09-11T15:08:35.69564Z","shell.execute_reply.started":"2022-09-11T15:08:35.513506Z","shell.execute_reply":"2022-09-11T15:08:35.694172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will do the same for the test data.","metadata":{}},{"cell_type":"code","source":"#creating our Y for the test data\nY_test = test[\"label\"]\n\n#creating our X for the training data\nX_test = test.drop(labels = [\"label\"],axis = 1) ","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.697333Z","iopub.execute_input":"2022-09-11T15:08:35.698178Z","iopub.status.idle":"2022-09-11T15:08:35.746218Z","shell.execute_reply.started":"2022-09-11T15:08:35.698129Z","shell.execute_reply":"2022-09-11T15:08:35.744789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Scaling Our Images","metadata":{}},{"cell_type":"markdown","source":"Next, we need to scale the data from 0-255 to 0-1. This will make things easier to work with the neural network because it will allow the nn to converge faster.","metadata":{}},{"cell_type":"code","source":"#converting the range of the pixel data from 0-255 to 0-1\nX_train = X_train / 255.0\n\nX_test = X_test / 255.0","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.748891Z","iopub.execute_input":"2022-09-11T15:08:35.749434Z","iopub.status.idle":"2022-09-11T15:08:35.866657Z","shell.execute_reply.started":"2022-09-11T15:08:35.74938Z","shell.execute_reply":"2022-09-11T15:08:35.864449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Reshaping Our Images","metadata":{}},{"cell_type":"markdown","source":"The images will need to be reshaped in order feed into our model. Our images will be 28x28 and, since we will be using grayscale, the color channel will be 1.","metadata":{}},{"cell_type":"code","source":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.870756Z","iopub.execute_input":"2022-09-11T15:08:35.871294Z","iopub.status.idle":"2022-09-11T15:08:35.880411Z","shell.execute_reply.started":"2022-09-11T15:08:35.871243Z","shell.execute_reply":"2022-09-11T15:08:35.878869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4 Distribution of Labels","metadata":{}},{"cell_type":"code","source":"#creating an interactive bar graph that shows the distrubition of labels within the training set\nfig = px.histogram(train, \n                   x='label', \n                   color = 'label',\n                   title=\"Distrubition of Labels in the Training Set\",\n                   width=700, height=500)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:35.882687Z","iopub.execute_input":"2022-09-11T15:08:35.883486Z","iopub.status.idle":"2022-09-11T15:08:36.405203Z","shell.execute_reply.started":"2022-09-11T15:08:35.883433Z","shell.execute_reply":"2022-09-11T15:08:36.403999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating an interactive bar graph that shows the distrubition of labels within the test set\nfig = px.histogram(test, \n                   x='label',\n                   color = 'label',\n                   title=\"Distrubition of Labels in the Test Set\",\n                   width=700, height=500)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:36.407564Z","iopub.execute_input":"2022-09-11T15:08:36.408165Z","iopub.status.idle":"2022-09-11T15:08:36.593808Z","shell.execute_reply.started":"2022-09-11T15:08:36.408109Z","shell.execute_reply":"2022-09-11T15:08:36.591771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our training images are fairly equally distrubited but unfortunatly our test images are not distrubited equally. It shouldn't prevent us from coming up with an accurate prediction but it is something to keep an eye on.\n\nThe label 9 and 25 columns are empty because they represent j and z and are not in the dataset.","metadata":{}},{"cell_type":"markdown","source":"# 4. Viewing the Images","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Training Images","metadata":{}},{"cell_type":"code","source":"#creating a 5x5 grid of the first 25 photos in the training images\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(X_train[i], cmap='gray')\n    plt.title(Y_train[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:36.596316Z","iopub.execute_input":"2022-09-11T15:08:36.597593Z","iopub.status.idle":"2022-09-11T15:08:38.198081Z","shell.execute_reply.started":"2022-09-11T15:08:36.597498Z","shell.execute_reply":"2022-09-11T15:08:38.196716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Test Images","metadata":{}},{"cell_type":"code","source":"#creating a 5x5 grid of the first 25 photos in the test images\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(X_test[i], cmap='gray')\n    plt.title(Y_test[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:38.202151Z","iopub.execute_input":"2022-09-11T15:08:38.202684Z","iopub.status.idle":"2022-09-11T15:08:39.271873Z","shell.execute_reply.started":"2022-09-11T15:08:38.202638Z","shell.execute_reply":"2022-09-11T15:08:39.270544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. CNN Model","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Spliting Our Training Data","metadata":{}},{"cell_type":"markdown","source":"We will take the images in the Train set and we will split them into training and validation sets. While training the model, we will use the new train set to train the model and the validation set to validate the results.\n\nOnce the model has been trained, we will take the pixel data from the test set and predict the labels for each test image. \n\nThen we will evaluate the model's performance by looking at a classification report.","metadata":{}},{"cell_type":"code","source":"#spliting training images into the images we will use for training the model and validating the model\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.3, random_state=7)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:39.273825Z","iopub.execute_input":"2022-09-11T15:08:39.274238Z","iopub.status.idle":"2022-09-11T15:08:39.771575Z","shell.execute_reply.started":"2022-09-11T15:08:39.274202Z","shell.execute_reply":"2022-09-11T15:08:39.769965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#showing the shapes of our train, validate, and test images\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_val.shape)\nprint(Y_val.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:39.773318Z","iopub.execute_input":"2022-09-11T15:08:39.773795Z","iopub.status.idle":"2022-09-11T15:08:39.782513Z","shell.execute_reply.started":"2022-09-11T15:08:39.773751Z","shell.execute_reply":"2022-09-11T15:08:39.780918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2 Creating Our Model","metadata":{}},{"cell_type":"code","source":"#creating our CNN model\nmodel = keras.Sequential([\n    \n    layers.BatchNormalization(),\n    layers.Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", padding='same',\n                  input_shape=[28, 28, 1]),\n    layers.MaxPool2D(),\n    layers.Dropout(.25),\n    \n    layers.BatchNormalization(),\n    layers.Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(.25),\n    \n    layers.BatchNormalization(),\n    layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(.25),\n\n    layers.BatchNormalization(),\n    layers.Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(.25),\n    \n    layers.Flatten(),\n    layers.Dropout(.25),\n    layers.Dense(units=64, activation=\"relu\"),\n    layers.Dense(units=26, activation=\"softmax\"),\n])","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:08:39.784598Z","iopub.execute_input":"2022-09-11T15:08:39.785811Z","iopub.status.idle":"2022-09-11T15:08:39.900912Z","shell.execute_reply.started":"2022-09-11T15:08:39.785748Z","shell.execute_reply":"2022-09-11T15:08:39.899657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compiling the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:10:29.058654Z","iopub.execute_input":"2022-09-11T15:10:29.059298Z","iopub.status.idle":"2022-09-11T15:10:29.074388Z","shell.execute_reply.started":"2022-09-11T15:10:29.059244Z","shell.execute_reply":"2022-09-11T15:10:29.072978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 Training Our Model","metadata":{}},{"cell_type":"code","source":"#Training the model\nhistory = model.fit(\n    x = X_train,\n    y = Y_train,\n    validation_data= (X_val,Y_val),\n    batch_size = 128,\n    epochs=50,\n    verbose=2,\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:10:32.543138Z","iopub.execute_input":"2022-09-11T15:10:32.543875Z","iopub.status.idle":"2022-09-11T15:20:56.200096Z","shell.execute_reply.started":"2022-09-11T15:10:32.543821Z","shell.execute_reply":"2022-09-11T15:20:56.198643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Viewing the training results\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:20:57.011907Z","iopub.execute_input":"2022-09-11T15:20:57.012498Z","iopub.status.idle":"2022-09-11T15:20:57.913956Z","shell.execute_reply.started":"2022-09-11T15:20:57.012413Z","shell.execute_reply":"2022-09-11T15:20:57.912462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Results","metadata":{}},{"cell_type":"markdown","source":"### 6.1 Classification Report","metadata":{}},{"cell_type":"code","source":"#creating our predictions using the test pixel values\npredictions = model.predict(X_test)\npredictions = np.argmax(predictions,axis = 1)\n\n#creating a report that show how our predictions compare with actual values\nprint(classification_report(Y_test, predictions))","metadata":{"execution":{"iopub.status.busy":"2022-09-11T15:21:06.643816Z","iopub.execute_input":"2022-09-11T15:21:06.644458Z","iopub.status.idle":"2022-09-11T15:21:08.387434Z","shell.execute_reply.started":"2022-09-11T15:21:06.644409Z","shell.execute_reply":"2022-09-11T15:21:08.386005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2 Brief Thoughts on Results","metadata":{}},{"cell_type":"markdown","source":"We were able to get an accuracy of 100% according to the classification report. \nThe biggest take away for me was that the BatchNormalization and Dropout layers really helped with increasing the accuracy. The Dropout layers seemed to really smooth out the training results as well.","metadata":{}},{"cell_type":"markdown","source":"# 7. Conclusion","metadata":{}},{"cell_type":"markdown","source":"### 7.1 Recap","metadata":{}},{"cell_type":"markdown","source":"We were able to take images of the American Sign Lanuage alphabet and use a CNN model to learn the alphabet and make predictions on new images. When training our CNN model, the training results were 99% accuracy but the validation results had an accuracy of 100%. When applying the CNN model on our test images we got the result of 100% accuracy.","metadata":{}},{"cell_type":"markdown","source":"### 7.2 Future Work","metadata":{}},{"cell_type":"markdown","source":"The next step would be to apply this model to live video feed to detect the American Sign Language alphabet within the video and translate each sign on the screen in real time.","metadata":{}}]}